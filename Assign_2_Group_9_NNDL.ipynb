{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPi/2Zdyv0daLC9AJVhtRIr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DantonCoote/My_Hub/blob/DeepLearning/Assign_2_Group_9_NNDL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2, Fruit Classification"
      ],
      "metadata": {
        "id": "hy7SoWz_s1EI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1.1, Loading and cleaning our Data"
      ],
      "metadata": {
        "id": "5M0dmKRgt6r0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "yga2SNrfsfw1",
        "outputId": "6cdf1a76-c99b-4ff3-e7e6-3b300bf2d306"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                AREA    PERIMETER   MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY  \\\n",
              "count     898.000000   898.000000   898.000000  898.000000    898.000000   \n",
              "mean   298295.207127  2057.660953   750.811994  495.872785      0.737468   \n",
              "std    107245.205337   410.012459   144.059326  114.268917      0.088727   \n",
              "min      1987.000000   911.828000   336.722700    2.283200      0.344800   \n",
              "25%    206948.000000  1726.091500   641.068650  404.684375      0.685625   \n",
              "50%    319833.000000  2196.345450   791.363400  495.054850      0.754700   \n",
              "75%    382573.000000  2389.716575   858.633750  589.031700      0.802150   \n",
              "max    546063.000000  2811.997100  1222.723000  766.453600      1.000000   \n",
              "\n",
              "          EQDIASQ    SOLIDITY    CONVEX_AREA      EXTENT  ASPECT_RATIO  ...  \\\n",
              "count  898.000000  898.000000     898.000000  898.000000    898.000000  ...   \n",
              "mean   604.577938    0.981840  303845.592428    0.736267      2.131102  ...   \n",
              "std    119.593888    0.018157  108815.656947    0.053745     17.820778  ...   \n",
              "min     50.298400    0.836600    2257.000000    0.512300      1.065300  ...   \n",
              "25%    513.317075    0.978825  210022.750000    0.705875      1.373725  ...   \n",
              "50%    638.140950    0.987300  327207.000000    0.746950      1.524150  ...   \n",
              "75%    697.930525    0.991800  388804.000000    0.775850      1.674750  ...   \n",
              "max    833.827900    0.997400  552598.000000    0.856200    535.525700  ...   \n",
              "\n",
              "           SkewRB  KurtosisRR  KurtosisRG  KurtosisRB     EntropyRR  \\\n",
              "count  898.000000  898.000000  898.000000  898.000000  8.980000e+02   \n",
              "mean     0.250518    4.247845    5.110894    3.780928 -3.185021e+10   \n",
              "std      0.632918    2.892357    3.745463    2.049831  2.037241e+10   \n",
              "min     -1.029100    1.708200    1.607600    1.767200 -1.091220e+11   \n",
              "25%     -0.196950    2.536625    2.508850    2.577275 -4.429444e+10   \n",
              "50%      0.135550    3.069800    3.127800    3.080700 -2.826156e+10   \n",
              "75%      0.593950    4.449850    7.320400    4.283125 -1.460482e+10   \n",
              "max      3.092300   26.171100   26.736700   32.249500 -1.627316e+08   \n",
              "\n",
              "          EntropyRG     EntropyRB  ALLdaub4RR  ALLdaub4RG  ALLdaub4RB  \n",
              "count  8.980000e+02  8.980000e+02  898.000000  898.000000  898.000000  \n",
              "mean  -2.901860e+10 -2.771876e+10   50.082888   48.805681   48.098393  \n",
              "std    1.712952e+10  1.484137e+10   16.063125   14.125911   10.813862  \n",
              "min   -9.261697e+10 -8.747177e+10   15.191100   20.524700   22.130000  \n",
              "25%   -3.894638e+10 -3.564534e+10   38.224425   38.654525   39.250725  \n",
              "50%   -2.620990e+10 -2.392928e+10   53.841300   50.337800   49.614100  \n",
              "75%   -1.433105e+10 -1.660367e+10   63.063350   59.573600   56.666675  \n",
              "max   -5.627727e+08 -4.370435e+08   79.828900   83.064900   74.104600  \n",
              "\n",
              "[8 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7083ff83-0069-4a32-a894-20557b55a7db\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AREA</th>\n",
              "      <th>PERIMETER</th>\n",
              "      <th>MAJOR_AXIS</th>\n",
              "      <th>MINOR_AXIS</th>\n",
              "      <th>ECCENTRICITY</th>\n",
              "      <th>EQDIASQ</th>\n",
              "      <th>SOLIDITY</th>\n",
              "      <th>CONVEX_AREA</th>\n",
              "      <th>EXTENT</th>\n",
              "      <th>ASPECT_RATIO</th>\n",
              "      <th>...</th>\n",
              "      <th>SkewRB</th>\n",
              "      <th>KurtosisRR</th>\n",
              "      <th>KurtosisRG</th>\n",
              "      <th>KurtosisRB</th>\n",
              "      <th>EntropyRR</th>\n",
              "      <th>EntropyRG</th>\n",
              "      <th>EntropyRB</th>\n",
              "      <th>ALLdaub4RR</th>\n",
              "      <th>ALLdaub4RG</th>\n",
              "      <th>ALLdaub4RB</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>898.000000</td>\n",
              "      <td>898.000000</td>\n",
              "      <td>898.000000</td>\n",
              "      <td>898.000000</td>\n",
              "      <td>898.000000</td>\n",
              "      <td>898.000000</td>\n",
              "      <td>898.000000</td>\n",
              "      <td>898.000000</td>\n",
              "      <td>898.000000</td>\n",
              "      <td>898.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>898.000000</td>\n",
              "      <td>898.000000</td>\n",
              "      <td>898.000000</td>\n",
              "      <td>898.000000</td>\n",
              "      <td>8.980000e+02</td>\n",
              "      <td>8.980000e+02</td>\n",
              "      <td>8.980000e+02</td>\n",
              "      <td>898.000000</td>\n",
              "      <td>898.000000</td>\n",
              "      <td>898.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>298295.207127</td>\n",
              "      <td>2057.660953</td>\n",
              "      <td>750.811994</td>\n",
              "      <td>495.872785</td>\n",
              "      <td>0.737468</td>\n",
              "      <td>604.577938</td>\n",
              "      <td>0.981840</td>\n",
              "      <td>303845.592428</td>\n",
              "      <td>0.736267</td>\n",
              "      <td>2.131102</td>\n",
              "      <td>...</td>\n",
              "      <td>0.250518</td>\n",
              "      <td>4.247845</td>\n",
              "      <td>5.110894</td>\n",
              "      <td>3.780928</td>\n",
              "      <td>-3.185021e+10</td>\n",
              "      <td>-2.901860e+10</td>\n",
              "      <td>-2.771876e+10</td>\n",
              "      <td>50.082888</td>\n",
              "      <td>48.805681</td>\n",
              "      <td>48.098393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>107245.205337</td>\n",
              "      <td>410.012459</td>\n",
              "      <td>144.059326</td>\n",
              "      <td>114.268917</td>\n",
              "      <td>0.088727</td>\n",
              "      <td>119.593888</td>\n",
              "      <td>0.018157</td>\n",
              "      <td>108815.656947</td>\n",
              "      <td>0.053745</td>\n",
              "      <td>17.820778</td>\n",
              "      <td>...</td>\n",
              "      <td>0.632918</td>\n",
              "      <td>2.892357</td>\n",
              "      <td>3.745463</td>\n",
              "      <td>2.049831</td>\n",
              "      <td>2.037241e+10</td>\n",
              "      <td>1.712952e+10</td>\n",
              "      <td>1.484137e+10</td>\n",
              "      <td>16.063125</td>\n",
              "      <td>14.125911</td>\n",
              "      <td>10.813862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1987.000000</td>\n",
              "      <td>911.828000</td>\n",
              "      <td>336.722700</td>\n",
              "      <td>2.283200</td>\n",
              "      <td>0.344800</td>\n",
              "      <td>50.298400</td>\n",
              "      <td>0.836600</td>\n",
              "      <td>2257.000000</td>\n",
              "      <td>0.512300</td>\n",
              "      <td>1.065300</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.029100</td>\n",
              "      <td>1.708200</td>\n",
              "      <td>1.607600</td>\n",
              "      <td>1.767200</td>\n",
              "      <td>-1.091220e+11</td>\n",
              "      <td>-9.261697e+10</td>\n",
              "      <td>-8.747177e+10</td>\n",
              "      <td>15.191100</td>\n",
              "      <td>20.524700</td>\n",
              "      <td>22.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>206948.000000</td>\n",
              "      <td>1726.091500</td>\n",
              "      <td>641.068650</td>\n",
              "      <td>404.684375</td>\n",
              "      <td>0.685625</td>\n",
              "      <td>513.317075</td>\n",
              "      <td>0.978825</td>\n",
              "      <td>210022.750000</td>\n",
              "      <td>0.705875</td>\n",
              "      <td>1.373725</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.196950</td>\n",
              "      <td>2.536625</td>\n",
              "      <td>2.508850</td>\n",
              "      <td>2.577275</td>\n",
              "      <td>-4.429444e+10</td>\n",
              "      <td>-3.894638e+10</td>\n",
              "      <td>-3.564534e+10</td>\n",
              "      <td>38.224425</td>\n",
              "      <td>38.654525</td>\n",
              "      <td>39.250725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>319833.000000</td>\n",
              "      <td>2196.345450</td>\n",
              "      <td>791.363400</td>\n",
              "      <td>495.054850</td>\n",
              "      <td>0.754700</td>\n",
              "      <td>638.140950</td>\n",
              "      <td>0.987300</td>\n",
              "      <td>327207.000000</td>\n",
              "      <td>0.746950</td>\n",
              "      <td>1.524150</td>\n",
              "      <td>...</td>\n",
              "      <td>0.135550</td>\n",
              "      <td>3.069800</td>\n",
              "      <td>3.127800</td>\n",
              "      <td>3.080700</td>\n",
              "      <td>-2.826156e+10</td>\n",
              "      <td>-2.620990e+10</td>\n",
              "      <td>-2.392928e+10</td>\n",
              "      <td>53.841300</td>\n",
              "      <td>50.337800</td>\n",
              "      <td>49.614100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>382573.000000</td>\n",
              "      <td>2389.716575</td>\n",
              "      <td>858.633750</td>\n",
              "      <td>589.031700</td>\n",
              "      <td>0.802150</td>\n",
              "      <td>697.930525</td>\n",
              "      <td>0.991800</td>\n",
              "      <td>388804.000000</td>\n",
              "      <td>0.775850</td>\n",
              "      <td>1.674750</td>\n",
              "      <td>...</td>\n",
              "      <td>0.593950</td>\n",
              "      <td>4.449850</td>\n",
              "      <td>7.320400</td>\n",
              "      <td>4.283125</td>\n",
              "      <td>-1.460482e+10</td>\n",
              "      <td>-1.433105e+10</td>\n",
              "      <td>-1.660367e+10</td>\n",
              "      <td>63.063350</td>\n",
              "      <td>59.573600</td>\n",
              "      <td>56.666675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>546063.000000</td>\n",
              "      <td>2811.997100</td>\n",
              "      <td>1222.723000</td>\n",
              "      <td>766.453600</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>833.827900</td>\n",
              "      <td>0.997400</td>\n",
              "      <td>552598.000000</td>\n",
              "      <td>0.856200</td>\n",
              "      <td>535.525700</td>\n",
              "      <td>...</td>\n",
              "      <td>3.092300</td>\n",
              "      <td>26.171100</td>\n",
              "      <td>26.736700</td>\n",
              "      <td>32.249500</td>\n",
              "      <td>-1.627316e+08</td>\n",
              "      <td>-5.627727e+08</td>\n",
              "      <td>-4.370435e+08</td>\n",
              "      <td>79.828900</td>\n",
              "      <td>83.064900</td>\n",
              "      <td>74.104600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 34 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7083ff83-0069-4a32-a894-20557b55a7db')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7083ff83-0069-4a32-a894-20557b55a7db button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7083ff83-0069-4a32-a894-20557b55a7db');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-836aaf86-aaaa-480b-bf62-c8f6a0d7c8f7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-836aaf86-aaaa-480b-bf62-c8f6a0d7c8f7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-836aaf86-aaaa-480b-bf62-c8f6a0d7c8f7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#beginning by loading our data\n",
        "data = pd.read_csv('Date_Fruit_Datasets.csv')\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a lot of data here! 34 columns and we see that there is some large deviations in our data, this is good as it will make training a classifier easier."
      ],
      "metadata": {
        "id": "GCGQ2t0huXwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j-XwSLttZAd",
        "outputId": "6110df41-6119-4256-c0f0-53abe808796a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 898 entries, 0 to 897\n",
            "Data columns (total 35 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   AREA           898 non-null    int64  \n",
            " 1   PERIMETER      898 non-null    float64\n",
            " 2   MAJOR_AXIS     898 non-null    float64\n",
            " 3   MINOR_AXIS     898 non-null    float64\n",
            " 4   ECCENTRICITY   898 non-null    float64\n",
            " 5   EQDIASQ        898 non-null    float64\n",
            " 6   SOLIDITY       898 non-null    float64\n",
            " 7   CONVEX_AREA    898 non-null    int64  \n",
            " 8   EXTENT         898 non-null    float64\n",
            " 9   ASPECT_RATIO   898 non-null    float64\n",
            " 10  ROUNDNESS      898 non-null    float64\n",
            " 11  COMPACTNESS    898 non-null    float64\n",
            " 12  SHAPEFACTOR_1  898 non-null    float64\n",
            " 13  SHAPEFACTOR_2  898 non-null    float64\n",
            " 14  SHAPEFACTOR_3  898 non-null    float64\n",
            " 15  SHAPEFACTOR_4  898 non-null    float64\n",
            " 16  MeanRR         898 non-null    float64\n",
            " 17  MeanRG         898 non-null    float64\n",
            " 18  MeanRB         898 non-null    float64\n",
            " 19  StdDevRR       898 non-null    float64\n",
            " 20  StdDevRG       898 non-null    float64\n",
            " 21  StdDevRB       898 non-null    float64\n",
            " 22  SkewRR         898 non-null    float64\n",
            " 23  SkewRG         898 non-null    float64\n",
            " 24  SkewRB         898 non-null    float64\n",
            " 25  KurtosisRR     898 non-null    float64\n",
            " 26  KurtosisRG     898 non-null    float64\n",
            " 27  KurtosisRB     898 non-null    float64\n",
            " 28  EntropyRR      898 non-null    float64\n",
            " 29  EntropyRG      898 non-null    int64  \n",
            " 30  EntropyRB      898 non-null    int64  \n",
            " 31  ALLdaub4RR     898 non-null    float64\n",
            " 32  ALLdaub4RG     898 non-null    float64\n",
            " 33  ALLdaub4RB     898 non-null    float64\n",
            " 34  Class          898 non-null    object \n",
            "dtypes: float64(30), int64(4), object(1)\n",
            "memory usage: 245.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking good for our data, no null values should be within it and we have a label known as Class that will help train accuracy"
      ],
      "metadata": {
        "id": "hUv7roCRurPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for duplicates\n",
        "dups = data.duplicated()\n",
        "for i in dups:\n",
        "  if i == True:\n",
        "    print(\"There are duplicates\")\n",
        "    break"
      ],
      "metadata": {
        "id": "jn1LWLJzt5qJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With no output we can assume there are no duplicates"
      ],
      "metadata": {
        "id": "e2zpZIybvSFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1.2, Data Exploration"
      ],
      "metadata": {
        "id": "YkVubmUAvfYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sb\n",
        "\n",
        "sb.barplot(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "6stTm-CAvQz1",
        "outputId": "5b6765f4-8579-4a98-bff4-49f0ed4f926b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This bar plot, though weird looking, shows that our data is not very well scaled. We have a wide variety of ranges for our numerical data which makes our bar plot seeem very scewed. We will need to scale the data before using it train a model or else we will have very inaccurate results (Speaking from experience)"
      ],
      "metadata": {
        "id": "jy0rYukjEbFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#moving labels to dataframe\n",
        "labels = data['Class']\n",
        "\n",
        "#dropping labels from original dataframe\n",
        "data_mod = data.drop('Class', axis=1)"
      ],
      "metadata": {
        "id": "XMwfR8zKvsC_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirming\n",
        "print(data_mod.info)\n",
        "labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UoIw5L0zHD2m",
        "outputId": "68bd7342-7651-454c-be32-6307e48fb4e7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method DataFrame.info of        AREA  PERIMETER  MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY   EQDIASQ  \\\n",
            "0    422163  2378.9080    837.8484    645.6693        0.6373  733.1539   \n",
            "1    338136  2085.1440    723.8198    595.2073        0.5690  656.1464   \n",
            "2    526843  2647.3940    940.7379    715.3638        0.6494  819.0222   \n",
            "3    416063  2351.2100    827.9804    645.2988        0.6266  727.8378   \n",
            "4    347562  2160.3540    763.9877    582.8359        0.6465  665.2291   \n",
            "..      ...        ...         ...         ...           ...       ...   \n",
            "893  255403  1925.3650    691.8453    477.1796        0.7241  570.2536   \n",
            "894  365924  2664.8230    855.4633    551.5447        0.7644  682.5752   \n",
            "895  254330  1926.7360    747.4943    435.6219        0.8126  569.0545   \n",
            "896  238955  1906.2679    716.6485    441.8297        0.7873  551.5859   \n",
            "897  343792  2289.2720    823.8438    534.7757        0.7607  661.6113   \n",
            "\n",
            "     SOLIDITY  CONVEX_AREA  EXTENT  ASPECT_RATIO  ...  SkewRB  KurtosisRR  \\\n",
            "0      0.9947       424428  0.7831        1.2976  ...  0.6019      3.2370   \n",
            "1      0.9974       339014  0.7795        1.2161  ...  0.4134      2.6228   \n",
            "2      0.9962       528876  0.7657        1.3150  ...  0.9183      3.7516   \n",
            "3      0.9948       418255  0.7759        1.2831  ...  1.8028      5.0401   \n",
            "4      0.9908       350797  0.7569        1.3108  ...  0.8865      2.7016   \n",
            "..        ...          ...     ...           ...  ...     ...         ...   \n",
            "893    0.9785       261028  0.7269        1.4499  ... -0.1398      2.2423   \n",
            "894    0.9466       386566  0.6695        1.5510  ...  0.5611      3.4109   \n",
            "895    0.9925       256255  0.7240        1.7159  ...  0.2665      2.2759   \n",
            "896    0.9604       248795  0.6954        1.6220  ...  0.5325      2.6769   \n",
            "897    0.9781       351472  0.6941        1.5405  ...  0.4318      2.5138   \n",
            "\n",
            "     KurtosisRG  KurtosisRB     EntropyRR    EntropyRG    EntropyRB  \\\n",
            "0        2.9574      4.2287 -5.919126e+10 -50714214400 -39922372608   \n",
            "1        2.6350      3.1704 -3.423307e+10 -37462601728 -31477794816   \n",
            "2        3.8611      4.7192 -9.394835e+10 -74738221056 -60311207936   \n",
            "3        8.6136      8.2618 -3.207431e+10 -32060925952 -29575010304   \n",
            "4        2.9761      4.4146 -3.998097e+10 -35980042240 -25593278464   \n",
            "..          ...         ...           ...          ...          ...   \n",
            "893      2.3704      2.7202 -2.529642e+10 -19168882688 -18473392128   \n",
            "894      3.5805      3.9910 -3.160522e+10 -21945366528 -19277905920   \n",
            "895      2.5090      2.6951 -2.224277e+10 -19594921984 -17592152064   \n",
            "896      2.6874      2.7991 -2.604860e+10 -21299822592 -19809978368   \n",
            "897      3.0369      3.0865 -3.198348e+10 -20482514944 -21219354624   \n",
            "\n",
            "     ALLdaub4RR  ALLdaub4RG  ALLdaub4RB  \n",
            "0       58.7255     54.9554     47.8400  \n",
            "1       50.0259     52.8168     47.8315  \n",
            "2       65.4772     59.2860     51.9378  \n",
            "3       43.3900     44.1259     41.1882  \n",
            "4       52.7743     50.9080     42.6666  \n",
            "..          ...         ...         ...  \n",
            "893     49.0869     43.0422     42.4153  \n",
            "894     46.8086     39.1046     36.5502  \n",
            "895     44.1325     40.7986     40.9769  \n",
            "896     51.2267     45.7162     45.6260  \n",
            "897     47.3454     38.6966     39.6738  \n",
            "\n",
            "[898 rows x 34 columns]>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    BERHI\n",
              "1    BERHI\n",
              "2    BERHI\n",
              "3    BERHI\n",
              "4    BERHI\n",
              "Name: Class, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BERHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BERHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BERHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BERHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BERHI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything looks good! We can move to the next phase of development."
      ],
      "metadata": {
        "id": "w7OYN7aQbOkm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1.3, Scaling and splitting our data"
      ],
      "metadata": {
        "id": "w98kGkGqtJGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "\n",
        "# splitting our data into training, validation, and testing variables\n",
        "# splitting\n",
        "train_x, rem_x, train_y, rem_y = model_selection.train_test_split(data_mod, labels, train_size=0.8)\n",
        "test_x, val_x, test_y, val_y = model_selection.train_test_split(rem_x, rem_y, train_size=0.5)"
      ],
      "metadata": {
        "id": "KiuPtW8Lv7tc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ensuring fair splits\n",
        "print(len(train_x), \"\\n\", len(test_x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2SwDft1KnvL",
        "outputId": "4c5d346c-bfee-4336-ad6a-ada6896d708e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "718 \n",
            " 90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quickly thinking about this..... 897 total entries so 718 is around 80% of our data and 90 is about 10%. Looks good!"
      ],
      "metadata": {
        "id": "e6WNWkAyK42s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "#initializing a scaler\n",
        "scalar = preprocessing.MinMaxScaler()\n",
        "\n",
        "# Scaling data\n",
        "train_x = scalar.fit_transform(train_x)\n",
        "test_x = scalar.transform(test_x)\n",
        "val_x = scalar.transform(val_x)"
      ],
      "metadata": {
        "id": "kDCQC5qiX101"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# enabling the encoder, from what I understand it automatically readjusts all labels from string\n",
        "# to numerical labels\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "test_y = encoder.transform(test_y)\n",
        "val_y = encoder.transform(val_y)"
      ],
      "metadata": {
        "id": "4bPWqUDBD9eM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(labels.unique()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLmvBJnxGowU",
        "outputId": "8fa2d1cb-3331-401d-82f5-764aa9fc0c30"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "train_y = keras.utils.to_categorical(train_y, 7)\n",
        "test_y = keras.utils.to_categorical(test_y, 7)\n",
        "val_y = keras.utils.to_categorical(val_y, 7)"
      ],
      "metadata": {
        "id": "7M4-KTonIQVD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are scaling the data to ensure all our datapoints are on the same scale, standardizing all the measurements of the dataset. We also split our data into Training, Testing, and Validation sets. We also encode our lables for easier usage in our classifier. <br>\n",
        "I am still trying to understand what exactly encoding does entirely as a whole. This is something we aren't covering in class at the moment and may not as we are studying with an earlier version of Tensorflow."
      ],
      "metadata": {
        "id": "VHshTBrEv-PO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2.1, Model Selection and Training"
      ],
      "metadata": {
        "id": "CVn5V2Sf1tz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Time to initialize an initial model\n",
        "from keras import models\n",
        "model = models.Sequential()"
      ],
      "metadata": {
        "id": "J-UwGmO02nq_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using a pandas dataframe to store important metrics\n",
        "stats = pd.DataFrame(columns=['Model', 'Validation Accuracy', 'Validation Loss', 'Confusion Matrix'])\n",
        "model_in = 0 # a global index I plan on using for recording every model made\n",
        "\n",
        "# building manually as I cannot be bothered to think about doing this in an automated fashion"
      ],
      "metadata": {
        "id": "vZdHTMrEfnrG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 1"
      ],
      "metadata": {
        "id": "G8S8hN24mogj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# beginning the building of our NN\n",
        "\n",
        "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
        "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
        "model.add(keras.layers.Dense(units=64, activation='relu'))\n",
        "model.add(keras.layers.Dense(units=32, activation='relu'))\n",
        "model.add(keras.layers.Dense(units=7, activation='softmax'))\n",
        "\n",
        "# Cool part is Dense layers are really flexible in this version of Keras so no\n",
        "# input layer or shape specifications are needed"
      ],
      "metadata": {
        "id": "WMik1GM96dj9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Ik9jJe2W6V3s"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is training our model completely\n",
        "history = model.fit(train_x, train_y, validation_data=(val_x,val_y), epochs=10)\n",
        "# storing the output for info gathering later!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Err8UVYSeowY",
        "outputId": "39e13567-ccd7-4a35-ab56-ce92d874bcfa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.4374 - loss: 1.7454 - val_accuracy: 0.6333 - val_loss: 1.1805\n",
            "Epoch 2/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6514 - loss: 1.0272 - val_accuracy: 0.6667 - val_loss: 0.7582\n",
            "Epoch 3/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7272 - loss: 0.7157 - val_accuracy: 0.8000 - val_loss: 0.6177\n",
            "Epoch 4/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7785 - loss: 0.5436 - val_accuracy: 0.7222 - val_loss: 0.7142\n",
            "Epoch 5/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7770 - loss: 0.5000 - val_accuracy: 0.7889 - val_loss: 0.5266\n",
            "Epoch 6/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8330 - loss: 0.4286 - val_accuracy: 0.8000 - val_loss: 0.5597\n",
            "Epoch 7/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8030 - loss: 0.4648 - val_accuracy: 0.8000 - val_loss: 0.5004\n",
            "Epoch 8/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8282 - loss: 0.4050 - val_accuracy: 0.8222 - val_loss: 0.4867\n",
            "Epoch 9/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8324 - loss: 0.4150 - val_accuracy: 0.8111 - val_loss: 0.4705\n",
            "Epoch 10/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8514 - loss: 0.3945 - val_accuracy: 0.8444 - val_loss: 0.4359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing out a summary of our compiled model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "Ctfdrv6DJ3nC",
        "outputId": "b7e6be75-38eb-401b-96b9-c72a20996b94"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚           \u001b[38;5;34m4,480\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 â”‚          \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚          \u001b[38;5;34m16,448\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  â”‚           \u001b[38;5;34m2,080\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   â”‚             \u001b[38;5;34m231\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,480</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m168,791\u001b[0m (659.34 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">168,791</span> (659.34 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m56,263\u001b[0m (219.78 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,263</span> (219.78 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m112,528\u001b[0m (439.57 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,528</span> (439.57 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing for gathering confusion matrix\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "ZEyHBTY1i_Hy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gathering data step for later comparison\n",
        "\n",
        "model_iteration = 'Model 1'\n",
        "acc = history.history['val_accuracy'][-1]\n",
        "loss = history.history['val_loss'][-1]\n",
        "\n",
        "# After training the model, get predictions on the validation set\n",
        "val_preds = model.predict(val_x)\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "val_pred_classes = np.argmax(val_preds, axis=1)\n",
        "val_y_classes = np.argmax(val_y, axis=1)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "con_max = confusion_matrix(val_y_classes, val_pred_classes)\n",
        "\n",
        "stats.loc[model_in] = [model_iteration, acc, loss, con_max]\n",
        "model_in = model_in+1 #moving index up one\n",
        "\n",
        "# for reference of column order\n",
        "#['Model', 'Validation Accuracy', 'Validation Loss', 'Confusion Matrix']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qAgdfzGfgV6",
        "outputId": "37f8c1cf-69eb-45cb-a07e-50198dfd3200"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cool results, now lets keep playing!\n",
        "My group partner and I went through this step proposing different tests to see what would happen when a given hyperparameter was changed or new layers were added/altered"
      ],
      "metadata": {
        "id": "muENc1c9NPMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 2"
      ],
      "metadata": {
        "id": "w8yhK0UemsAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = keras.models.Sequential([\n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(125, activation='relu'),\n",
        "    keras.layers.Dense(7, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "sir3UsSANOe0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "t-VJ_ojYOzY7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# second attempt at fresh model design\n",
        "history = model2.fit(train_x, train_y, validation_data=(val_x,val_y), epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AeBbriiP9PB",
        "outputId": "a87fdd0a-e2aa-4fd4-d44e-b5cfafcb5f18"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.3140 - loss: 1.7466 - val_accuracy: 0.6222 - val_loss: 1.0903\n",
            "Epoch 2/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6637 - loss: 1.0001 - val_accuracy: 0.7667 - val_loss: 0.6394\n",
            "Epoch 3/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7639 - loss: 0.6383 - val_accuracy: 0.7778 - val_loss: 0.5510\n",
            "Epoch 4/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7974 - loss: 0.5418 - val_accuracy: 0.7222 - val_loss: 0.6047\n",
            "Epoch 5/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8370 - loss: 0.4621 - val_accuracy: 0.8111 - val_loss: 0.4902\n",
            "Epoch 6/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8332 - loss: 0.4330 - val_accuracy: 0.8111 - val_loss: 0.4294\n",
            "Epoch 7/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8219 - loss: 0.4282 - val_accuracy: 0.7444 - val_loss: 0.5708\n",
            "Epoch 8/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8193 - loss: 0.4470 - val_accuracy: 0.8111 - val_loss: 0.4328\n",
            "Epoch 9/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8533 - loss: 0.3699 - val_accuracy: 0.8444 - val_loss: 0.3676\n",
            "Epoch 10/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8968 - loss: 0.3192 - val_accuracy: 0.8667 - val_loss: 0.3693\n",
            "Epoch 11/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8809 - loss: 0.2921 - val_accuracy: 0.8778 - val_loss: 0.4125\n",
            "Epoch 12/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8634 - loss: 0.3398 - val_accuracy: 0.8556 - val_loss: 0.3795\n",
            "Epoch 13/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8702 - loss: 0.3145 - val_accuracy: 0.8444 - val_loss: 0.3903\n",
            "Epoch 14/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8667 - loss: 0.3113 - val_accuracy: 0.8889 - val_loss: 0.3347\n",
            "Epoch 15/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8769 - loss: 0.3009 - val_accuracy: 0.8444 - val_loss: 0.4381\n",
            "Epoch 16/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8700 - loss: 0.3251 - val_accuracy: 0.8556 - val_loss: 0.3498\n",
            "Epoch 17/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8602 - loss: 0.2967 - val_accuracy: 0.8444 - val_loss: 0.3688\n",
            "Epoch 18/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9056 - loss: 0.2710 - val_accuracy: 0.8889 - val_loss: 0.3374\n",
            "Epoch 19/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8717 - loss: 0.3250 - val_accuracy: 0.8556 - val_loss: 0.3775\n",
            "Epoch 20/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8633 - loss: 0.3021 - val_accuracy: 0.8667 - val_loss: 0.3174\n",
            "Epoch 21/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9078 - loss: 0.2663 - val_accuracy: 0.8778 - val_loss: 0.3232\n",
            "Epoch 22/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8971 - loss: 0.2854 - val_accuracy: 0.8444 - val_loss: 0.3368\n",
            "Epoch 23/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9023 - loss: 0.2606 - val_accuracy: 0.8444 - val_loss: 0.3504\n",
            "Epoch 24/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9100 - loss: 0.2289 - val_accuracy: 0.8667 - val_loss: 0.3033\n",
            "Epoch 25/25\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8903 - loss: 0.2764 - val_accuracy: 0.7667 - val_loss: 0.5416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "p4o2yL_JQHiG",
        "outputId": "0009028f-1bd4-46cc-89e2-6cda4d351e2f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 â”‚          \u001b[38;5;34m17,920\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 â”‚         \u001b[38;5;34m131,328\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m)                 â”‚          \u001b[38;5;34m32,125\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   â”‚             \u001b[38;5;34m882\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,920</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>)                 â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,125</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">882</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m546,767\u001b[0m (2.09 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">546,767</span> (2.09 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m182,255\u001b[0m (711.93 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">182,255</span> (711.93 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m364,512\u001b[0m (1.39 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">364,512</span> (1.39 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gathering data step for later comparison\n",
        "\n",
        "model_iteration = 'Model 2'\n",
        "acc = history.history['val_accuracy'][-1]\n",
        "loss = history.history['val_loss'][-1]\n",
        "\n",
        "# After training the model, get predictions on the validation set\n",
        "val_preds = model2.predict(val_x)\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "val_pred_classes = np.argmax(val_preds, axis=1)\n",
        "val_y_classes = np.argmax(val_y, axis=1)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "con_max = confusion_matrix(val_y_classes, val_pred_classes)\n",
        "\n",
        "stats.loc[model_in] = [model_iteration, acc, loss, con_max]\n",
        "model_in = model_in+1 #moving index up one\n",
        "\n",
        "# for reference of column order\n",
        "#['Model', 'Validation Accuracy', 'Validation Loss', 'Confusion Matrix']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VzQKt8Il7BH",
        "outputId": "8ba0b7eb-cc1b-4e36-fa40-602104a4cbf5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 3"
      ],
      "metadata": {
        "id": "cLhiCvI5muxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = models.Sequential()\n",
        "\n",
        "model3.add(keras.layers.Dense(units=128, activation='relu'))\n",
        "model3.add(keras.layers.Dense(units=256, activation='relu'))\n",
        "model3.add(keras.layers.Dense(units=64, activation='relu'))\n",
        "model3.add(keras.layers.Dense(units=32, activation='relu'))\n",
        "model3.add(keras.layers.Dense(units=7, activation='softmax'))\n",
        "\n",
        "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "OBW2PxeHQQFL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seeing how more epochs affects our first model\n",
        "history = model3.fit(train_x, train_y, validation_data=(val_x,val_y), epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kROWBXWR0P7",
        "outputId": "63a4d6c2-b42b-4e7e-f352-f18a70c63b6b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.3292 - loss: 1.8262 - val_accuracy: 0.6000 - val_loss: 1.4268\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6258 - loss: 1.2675 - val_accuracy: 0.6556 - val_loss: 0.9738\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7126 - loss: 0.8154 - val_accuracy: 0.7111 - val_loss: 0.7297\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7876 - loss: 0.5515 - val_accuracy: 0.7556 - val_loss: 0.6484\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7891 - loss: 0.5364 - val_accuracy: 0.7556 - val_loss: 0.6860\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8139 - loss: 0.5069 - val_accuracy: 0.8111 - val_loss: 0.5726\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8425 - loss: 0.4151 - val_accuracy: 0.8222 - val_loss: 0.4805\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8279 - loss: 0.3902 - val_accuracy: 0.8222 - val_loss: 0.4763\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8279 - loss: 0.3683 - val_accuracy: 0.8000 - val_loss: 0.4899\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8317 - loss: 0.4322 - val_accuracy: 0.7556 - val_loss: 0.5351\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8112 - loss: 0.4341 - val_accuracy: 0.8556 - val_loss: 0.4405\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8659 - loss: 0.3418 - val_accuracy: 0.8333 - val_loss: 0.4190\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8393 - loss: 0.3824 - val_accuracy: 0.7889 - val_loss: 0.4836\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8861 - loss: 0.3045 - val_accuracy: 0.8222 - val_loss: 0.4412\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8927 - loss: 0.2862 - val_accuracy: 0.8556 - val_loss: 0.4253\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8511 - loss: 0.3379 - val_accuracy: 0.8333 - val_loss: 0.4093\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8835 - loss: 0.2959 - val_accuracy: 0.8556 - val_loss: 0.3977\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8825 - loss: 0.2831 - val_accuracy: 0.8222 - val_loss: 0.4720\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8690 - loss: 0.3156 - val_accuracy: 0.8778 - val_loss: 0.3667\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8636 - loss: 0.3238 - val_accuracy: 0.8667 - val_loss: 0.3849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seems more epochs can improve our accuracy, though the gains are limited\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "zirIabLmSzf6",
        "outputId": "21107025-4481-4395-d9ec-005a185c77d9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚           \u001b[38;5;34m4,480\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 â”‚          \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚          \u001b[38;5;34m16,448\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  â”‚           \u001b[38;5;34m2,080\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   â”‚             \u001b[38;5;34m231\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,480</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m168,791\u001b[0m (659.34 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">168,791</span> (659.34 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m56,263\u001b[0m (219.78 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,263</span> (219.78 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m112,528\u001b[0m (439.57 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,528</span> (439.57 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gathering data step for later comparison\n",
        "\n",
        "model_iteration = 'Model 3'\n",
        "acc = history.history['val_accuracy'][-1]\n",
        "loss = history.history['val_loss'][-1]\n",
        "\n",
        "# After training the model, get predictions on the validation set\n",
        "val_preds = model3.predict(val_x)\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "val_pred_classes = np.argmax(val_preds, axis=1)\n",
        "val_y_classes = np.argmax(val_y, axis=1)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "con_max = confusion_matrix(val_y_classes, val_pred_classes)\n",
        "\n",
        "stats.loc[model_in] = [model_iteration, acc, loss, con_max]\n",
        "model_in = model_in+1 #moving index up one\n",
        "\n",
        "# for reference of column order\n",
        "#['Model', 'Validation Accuracy', 'Validation Loss', 'Confusion Matrix']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQGl1hDmmJjp",
        "outputId": "5ef7b521-68e1-4c48-807f-5ee4cb8b3bb0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ce326834ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/3\u001b[0m \u001b[32mâ”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 75ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ce326834ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 4"
      ],
      "metadata": {
        "id": "IUd73HJ_myyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = models.Sequential()\n",
        "\n",
        "model4.add(keras.layers.Dense(units=128, activation='relu'))\n",
        "model4.add(keras.layers.Dense(units=256, activation='relu'))\n",
        "model4.add(keras.layers.Dense(units=64, activation='relu'))\n",
        "model4.add(keras.layers.Dense(units=32, activation='relu'))\n",
        "model4.add(keras.layers.Dense(units=7, activation='softmax'))\n",
        "\n",
        "model4.compile(optimizer='lion', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ZHeCuBfoTGPM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing a different optimizer!\n",
        "history = model4.fit(train_x, train_y, validation_data=(val_x,val_y), epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5USD3Y3OWULo",
        "outputId": "2f3a77b7-129a-4c95-c08b-3a94d8c16c57"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.4331 - loss: 1.7170 - val_accuracy: 0.6333 - val_loss: 1.1298\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6621 - loss: 0.9270 - val_accuracy: 0.7556 - val_loss: 0.6232\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7609 - loss: 0.5812 - val_accuracy: 0.7556 - val_loss: 0.5509\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8139 - loss: 0.4711 - val_accuracy: 0.7667 - val_loss: 0.6621\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8467 - loss: 0.4121 - val_accuracy: 0.7667 - val_loss: 0.6750\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8592 - loss: 0.4021 - val_accuracy: 0.8222 - val_loss: 0.5187\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8649 - loss: 0.3363 - val_accuracy: 0.8111 - val_loss: 0.5158\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8629 - loss: 0.3592 - val_accuracy: 0.8111 - val_loss: 0.4913\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8609 - loss: 0.3181 - val_accuracy: 0.7889 - val_loss: 0.5459\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8559 - loss: 0.3267 - val_accuracy: 0.7778 - val_loss: 0.5108\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8970 - loss: 0.2676 - val_accuracy: 0.8667 - val_loss: 0.4659\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8930 - loss: 0.2894 - val_accuracy: 0.8889 - val_loss: 0.3434\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9131 - loss: 0.2136 - val_accuracy: 0.8667 - val_loss: 0.5709\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8918 - loss: 0.2784 - val_accuracy: 0.8667 - val_loss: 0.4304\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9137 - loss: 0.2225 - val_accuracy: 0.8889 - val_loss: 0.3219\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9303 - loss: 0.1701 - val_accuracy: 0.8778 - val_loss: 0.3571\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9298 - loss: 0.1766 - val_accuracy: 0.9000 - val_loss: 0.3195\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9469 - loss: 0.1815 - val_accuracy: 0.8556 - val_loss: 0.4738\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9429 - loss: 0.1583 - val_accuracy: 0.8556 - val_loss: 0.4420\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9245 - loss: 0.1891 - val_accuracy: 0.8667 - val_loss: 0.4459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seems the lion optimizer is good at its job!\n",
        "model4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "aWD-qFsDWbr8",
        "outputId": "5aebddd2-fe7c-438f-8ba8-c24bb7ae5f73"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚           \u001b[38;5;34m4,480\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 â”‚          \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚          \u001b[38;5;34m16,448\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  â”‚           \u001b[38;5;34m2,080\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_18 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   â”‚             \u001b[38;5;34m231\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,480</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,528\u001b[0m (439.57 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,528</span> (439.57 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m56,263\u001b[0m (219.78 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,263</span> (219.78 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m56,265\u001b[0m (219.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,265</span> (219.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gathering data step for later comparison\n",
        "\n",
        "model_iteration = 'Model 4'\n",
        "acc = history.history['val_accuracy'][-1]\n",
        "loss = history.history['val_loss'][-1]\n",
        "\n",
        "# After training the model, get predictions on the validation set\n",
        "val_preds = model4.predict(val_x)\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "val_pred_classes = np.argmax(val_preds, axis=1)\n",
        "val_y_classes = np.argmax(val_y, axis=1)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "con_max = confusion_matrix(val_y_classes, val_pred_classes)\n",
        "\n",
        "stats.loc[model_in] = [model_iteration, acc, loss, con_max]\n",
        "model_in = model_in+1 #moving index up one\n",
        "\n",
        "# for reference of column order\n",
        "#['Model', 'Validation Accuracy', 'Validation Loss', 'Confusion Matrix']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJR4yoj-mRRy",
        "outputId": "011bddb3-ab2d-4c21-bd68-5f42103dc0bf"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 5"
      ],
      "metadata": {
        "id": "LRsasotbm14Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# making a crazy experiment with this one!! Using Abi's baby with Lion!\n",
        "# will learn more layers eventually!\n",
        "model5 = keras.models.Sequential([\n",
        "    keras.layers.Dense(1024, activation='relu'),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "# we have way more loss functions than I originally thought!\n",
        "model5.compile(optimizer='lion', loss='categorical_focal_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "IjScogf_WrMQ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model5.fit(train_x, train_y, validation_data=(val_x,val_y), epochs=20, batch_size=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Llehh5JZhX5",
        "outputId": "3990535e-98e3-4ee4-8307-33be1c7d354c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.4103 - loss: 0.2776 - val_accuracy: 0.7111 - val_loss: 0.0926\n",
            "Epoch 2/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7377 - loss: 0.0870 - val_accuracy: 0.7889 - val_loss: 0.0816\n",
            "Epoch 3/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7791 - loss: 0.0604 - val_accuracy: 0.7444 - val_loss: 0.0709\n",
            "Epoch 4/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8122 - loss: 0.0500 - val_accuracy: 0.8444 - val_loss: 0.0526\n",
            "Epoch 5/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7859 - loss: 0.0489 - val_accuracy: 0.8333 - val_loss: 0.0481\n",
            "Epoch 6/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7968 - loss: 0.0442 - val_accuracy: 0.8111 - val_loss: 0.0421\n",
            "Epoch 7/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8305 - loss: 0.0403 - val_accuracy: 0.8333 - val_loss: 0.0497\n",
            "Epoch 8/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8263 - loss: 0.0400 - val_accuracy: 0.8556 - val_loss: 0.0430\n",
            "Epoch 9/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7866 - loss: 0.0496 - val_accuracy: 0.8222 - val_loss: 0.0454\n",
            "Epoch 10/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8624 - loss: 0.0398 - val_accuracy: 0.7778 - val_loss: 0.0486\n",
            "Epoch 11/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8105 - loss: 0.0441 - val_accuracy: 0.8444 - val_loss: 0.0399\n",
            "Epoch 12/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8371 - loss: 0.0451 - val_accuracy: 0.8333 - val_loss: 0.0504\n",
            "Epoch 13/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8271 - loss: 0.0369 - val_accuracy: 0.8333 - val_loss: 0.0399\n",
            "Epoch 14/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8578 - loss: 0.0353 - val_accuracy: 0.8333 - val_loss: 0.0447\n",
            "Epoch 15/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8399 - loss: 0.0363 - val_accuracy: 0.8667 - val_loss: 0.0431\n",
            "Epoch 16/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8341 - loss: 0.0367 - val_accuracy: 0.8222 - val_loss: 0.0436\n",
            "Epoch 17/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8524 - loss: 0.0358 - val_accuracy: 0.8222 - val_loss: 0.0448\n",
            "Epoch 18/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8459 - loss: 0.0380 - val_accuracy: 0.8000 - val_loss: 0.0507\n",
            "Epoch 19/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8358 - loss: 0.0353 - val_accuracy: 0.8333 - val_loss: 0.0437\n",
            "Epoch 20/20\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8538 - loss: 0.0381 - val_accuracy: 0.8333 - val_loss: 0.0373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "ROYAmgn4Z4lp",
        "outputId": "ef14a0f5-d752-4b97-e6f3-8bc20255b8a3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_19 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                â”‚          \u001b[38;5;34m35,840\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 â”‚         \u001b[38;5;34m262,400\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚          \u001b[38;5;34m16,448\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   â”‚             \u001b[38;5;34m455\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">35,840</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">455</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m630,288\u001b[0m (2.40 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">630,288</span> (2.40 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m315,143\u001b[0m (1.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">315,143</span> (1.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m315,145\u001b[0m (1.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">315,145</span> (1.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gathering data step for later comparison\n",
        "\n",
        "model_iteration = 'Model 5'\n",
        "acc = history.history['val_accuracy'][-1]\n",
        "loss = history.history['val_loss'][-1]\n",
        "\n",
        "# After training the model, get predictions on the validation set\n",
        "val_preds = model5.predict(val_x)\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "val_pred_classes = np.argmax(val_preds, axis=1)\n",
        "val_y_classes = np.argmax(val_y, axis=1)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "con_max = confusion_matrix(val_y_classes, val_pred_classes)\n",
        "\n",
        "stats.loc[model_in] = [model_iteration, acc, loss, con_max]\n",
        "model_in = model_in+1 #moving index up one\n",
        "\n",
        "# for reference of column order\n",
        "#['Model', 'Validation Accuracy', 'Validation Loss', 'Confusion Matrix']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK7FgZBKac8y",
        "outputId": "7cdfe68f-fba5-4019-cd7f-ace9a0ba13f5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2.2, Choosing the best model"
      ],
      "metadata": {
        "id": "3dRLUbLqm-bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bENmWD2UnDcv",
        "outputId": "5113b895-43ae-4071-83d4-73153449c6e8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Model  Validation Accuracy  Validation Loss  \\\n",
            "0  Model 1             0.844444         0.435869   \n",
            "1  Model 2             0.766667         0.541642   \n",
            "2  Model 3             0.866667         0.384923   \n",
            "3  Model 4             0.866667         0.445916   \n",
            "4  Model 5             0.833333         0.037262   \n",
            "\n",
            "                                    Confusion Matrix  \n",
            "0  [[1, 0, 0, 3, 2, 0, 0], [0, 10, 1, 0, 0, 1, 2]...  \n",
            "1  [[4, 0, 0, 2, 0, 0, 0], [0, 2, 0, 0, 0, 1, 11]...  \n",
            "2  [[2, 0, 0, 3, 1, 0, 0], [0, 9, 1, 0, 1, 1, 2],...  \n",
            "3  [[4, 0, 0, 2, 0, 0, 0], [0, 10, 1, 0, 0, 1, 2]...  \n",
            "4  [[4, 0, 0, 1, 1, 0, 0], [0, 6, 2, 0, 0, 0, 6],...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Which model is best?\n",
        "Model 3 seems to be our best one? Were the others overfitting? Possibly! But with these results we see that Model 3 looks like our best result BUT Model 4 was a star in training and we feel we cannot discount that fact, so we are testing both for Models for accuracy"
      ],
      "metadata": {
        "id": "FZPUTLgPnXSE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2.3, Testing Models 3 and 4"
      ],
      "metadata": {
        "id": "VKPfKPoeoXQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# After training the model, get predictions on the validation set\n",
        "test_preds = model3.predict(test_x)\n",
        "\n",
        "\n",
        "# Convert predicted probabilities to class labels, Learning why this is needed still\n",
        "# potentially something that is apart of newer Keras\n",
        "test_pred_classes = np.argmax(test_preds, axis=1)\n",
        "test_y_classes = np.argmax(test_y, axis=1)\n",
        "\n",
        "# Computing accuracy\n",
        "acc = accuracy_score(test_y_classes, test_pred_classes)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "con_max = confusion_matrix(test_y_classes, test_pred_classes)\n",
        "\n",
        "# Printing scores\n",
        "print('Accuracy: ', acc, '\\nConfusion Matrix:\\n', con_max)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_26EInl1nQwB",
        "outputId": "8b95edbb-cf57-4b66-e20d-9051caeb6d57"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Accuracy:  0.8666666666666667 \n",
            "Confusion Matrix:\n",
            " [[ 5  0  0  1  3  0  0]\n",
            " [ 0 10  1  0  0  0  1]\n",
            " [ 0  0 18  0  0  0  0]\n",
            " [ 2  0  0  4  0  0  0]\n",
            " [ 0  1  0  0 12  0  0]\n",
            " [ 0  0  0  0  0 23  0]\n",
            " [ 0  2  0  0  1  0  6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After training the model, get predictions on the validation set\n",
        "test_preds = model4.predict(test_x)\n",
        "\n",
        "\n",
        "# Convert predicted probabilities to class labels, Learning why this is needed still\n",
        "# potentially something that is apart of newer Keras\n",
        "test_pred_classes = np.argmax(test_preds, axis=1)\n",
        "test_y_classes = np.argmax(test_y, axis=1)\n",
        "\n",
        "# Computing accuracy\n",
        "acc = accuracy_score(test_y_classes, test_pred_classes)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "con_max = confusion_matrix(test_y_classes, test_pred_classes)\n",
        "\n",
        "# Printing scores\n",
        "print('Accuracy: ', acc, '\\nConfusion Matrix:\\n', con_max)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VcWE1cgpVvi",
        "outputId": "f1274635-524d-44ab-e19d-7c31087cf812"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Accuracy:  0.9 \n",
            "Confusion Matrix:\n",
            " [[ 8  0  0  1  0  0  0]\n",
            " [ 0 10  1  0  0  0  1]\n",
            " [ 0  1 17  0  0  0  0]\n",
            " [ 1  0  0  5  0  0  0]\n",
            " [ 0  1  0  0 12  0  0]\n",
            " [ 0  0  0  0  0 23  0]\n",
            " [ 0  3  0  0  0  0  6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3.1, Conclusions"
      ],
      "metadata": {
        "id": "mr6gZWGErPY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4 is our champion!\n",
        "We feel Model 4 is our best due to the massive jump in accuracy. Why is preforms better for the Test data versus Model 3, which preforms similar to it's validation scores, is interesting and something neither of us can fully explain at the moment. Judging from the confusion matrices, Model 4 simply has fewer false categorizations in a few categories. Overall Model 4 has fewer mistakes, suggesting it has better decision boundaries for for fruits that are on the boundaries of our classifications. We likely could have seent this better if I had printed the Confusion Matrices out in a more readable manor! Lesson learned for next time!"
      ],
      "metadata": {
        "id": "w7RGFFacraN2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3.2, Use case preformance?\n",
        "Well, with an accuracy of 90% and a a confusion matrix that shows us that this model has well defined descision boundaries for it labels we can assume that this model would preform well in the real world. Perhaps having more data to ensure accuracy would be nice. We are hesitant to say that this model is prefect for it's role as statistically it will misplace 1/10 fruits if used in sorting but for basic identification purposes it should be an effective solution. <br>\n",
        "If we are using this solution for low risk sorting, like potato qualities, this model is effective but if this model is being deployed to prevent cross contamination of allergens, specifically considering peanuts in this hypathetical, this model would be inadequate as the risk may be too great for a cross contamination event. <br>\n",
        "<br>Low Risk applications: Acceptable<br>\n",
        "High Risk applications: Further improvement is required"
      ],
      "metadata": {
        "id": "Rcx_fI-CudqS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rok-7-jBqrhw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}